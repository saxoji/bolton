{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/saxoji/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'THE LONG MARCH TO A WEST WING CORNER OFFICE.\\nOne attraction of being National Security Advisor is the sheer multiplicity and volume of challenges that confront you. If you don’t like turmoil, uncertainty, and risk—all while being constantly overwhelmed with information, decisions to be made, and the'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "parse_text = open('/Users/saxoji/Downloads/extract/Bolton/all-txt/BOLTON_ChapterAll.txt', 'r').read()\n",
    "parse_text[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플의 개수 : 7350\n",
      "['the', 'long', 'march', 'to', 'a', 'west', 'wing', 'corner', 'office']\n",
      "['one', 'attraction', 'of', 'being', 'national', 'security', 'advisor', 'is', 'the', 'sheer', 'multiplicity', 'and', 'volume', 'of', 'challenges', 'that', 'confront', 'you']\n",
      "['if', 'you', 'don', 't', 'like', 'turmoil', 'uncertainty', 'and', 'risk', 'all', 'while', 'being', 'constantly', 'overwhelmed', 'with', 'information', 'decisions', 'to', 'be', 'made', 'and', 'the', 'sheer', 'amount', 'of', 'work', 'and', 'enlivened', 'by', 'international', 'and', 'domestic', 'personality', 'and', 'ego', 'conflicts', 'beyond', 'description', 'try', 'something', 'else']\n"
     ]
    }
   ],
   "source": [
    "sent_text=sent_tokenize(parse_text)\n",
    "\n",
    "normalized_text = []\n",
    "for string in sent_text:\n",
    "     tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\n",
    "     normalized_text.append(tokens)\n",
    "    \n",
    "result = [word_tokenize(sentence) for sentence in normalized_text]\n",
    "print('총 샘플의 개수 : {}'.format(len(result)))\n",
    "for line in result[:3]: # 샘플 3개만 출력\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('pompeo', 0.9929609894752502), ('me', 0.9914903044700623), ('kelly', 0.9872748851776123), ('him', 0.9867581129074097), ('told', 0.9796295166015625), ('dunford', 0.9769812822341919), ('mattis', 0.9718626141548157), ('agreed', 0.9701361060142517), ('tell', 0.9701154828071594), ('call', 0.969874918460846)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(sentences=result, size=100, window=5, min_count=5, workers=4, sg=0)\n",
    "model_result = model.wv.most_similar(\"trump\")\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-25 19:52:47,649 - word2vec2tensor - INFO - running /Users/saxoji/opt/anaconda3/lib/python3.7/site-packages/gensim/scripts/word2vec2tensor.py --input bolton_w2v --output bolton_w2v\n",
      "2020-06-25 19:52:47,649 - utils_any2vec - INFO - loading projection weights from bolton_w2v\n",
      "2020-06-25 19:52:47,970 - utils_any2vec - INFO - loaded (3329, 100) matrix from bolton_w2v\n",
      "2020-06-25 19:52:48,266 - word2vec2tensor - INFO - 2D tensor file saved to bolton_w2v_tensor.tsv\n",
      "2020-06-25 19:52:48,266 - word2vec2tensor - INFO - Tensor metadata file saved to bolton_w2v_metadata.tsv\n",
      "2020-06-25 19:52:48,266 - word2vec2tensor - INFO - finished running word2vec2tensor.py\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "model.wv.save_word2vec_format('bolton_w2v') # 모델 저장\n",
    "# loaded_model = KeyedVectors.load_word2vec_format(\"bolton_w2v\") # 모델 로드\n",
    "!python -m gensim.scripts.word2vec2tensor --input bolton_w2v --output bolton_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
